{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2024-11-23 22:20:17,963\u001b[0m:     Asyncio event loop already running.\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:17,964\u001b[0m:     Logger propagate set to False\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:17,965\u001b[0m:     Pre-registering run with id 537985701173157333\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:17,966\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:17,966\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:17,967\u001b[0m:     Buffer time delay: 5s\n",
      "\u001b[92mINFO 2024-11-23 22:20:17,969\u001b[0m:      Starting Flower ServerApp, config: num_rounds=50, no round_timeout\n",
      "\u001b[92mINFO 2024-11-23 22:20:17,970\u001b[0m:      \n",
      "\u001b[92mINFO 2024-11-23 22:20:17,971\u001b[0m:      [INIT]\n",
      "\u001b[92mINFO 2024-11-23 22:20:17,971\u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO 2024-11-23 22:20:17,972\u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO 2024-11-23 22:20:17,973\u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO 2024-11-23 22:20:17,973\u001b[0m:      \n",
      "\u001b[92mINFO 2024-11-23 22:20:17,973\u001b[0m:      [ROUND 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Scenario: Baseline_IID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mDEBUG 2024-11-23 22:20:22,968\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:22,969\u001b[0m:     Registered 5 nodes\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:22,969\u001b[0m:     Supported backends: ['ray']\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:22,970\u001b[0m:     Initialising: RayBackend\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:22,970\u001b[0m:     Backend config: {'init_args': {}, 'client_resources': {'num_cpus': 2, 'num_gpus': 0}, 'actor': {'tensorflow': 0}}\n",
      "2024-11-23 22:20:23,754\tINFO worker.py:1819 -- Started a local Ray instance.\n",
      "\u001b[92mINFO 2024-11-23 22:20:24,435\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 5)\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:24,447\u001b[0m:     Constructed ActorPool with: 16 actors\n",
      "\u001b[94mDEBUG 2024-11-23 22:20:24,448\u001b[0m:     Using InMemoryState\n",
      "\u001b[36m(ClientAppActor pid=908917)\u001b[0m /home/fredrik/BTH/DV2607/part2/flower_env/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=908917)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[92mINFO 2024-11-23 22:20:34,054\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[93mWARNING 2024-11-23 22:20:34,109\u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO 2024-11-23 22:20:34,110\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
      "\u001b[36m(ClientAppActor pid=908917)\u001b[0m /home/fredrik/BTH/DV2607/part2/flower_env/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=908917)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[92mINFO 2024-11-23 22:20:41,925\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-11-23 22:20:41,925\u001b[0m:      Round 1 evaluation metrics:\n",
      "\u001b[92mINFO 2024-11-23 22:20:41,926\u001b[0m:      Accuracy: 0.3230\n",
      "\u001b[92mINFO 2024-11-23 22:20:41,927\u001b[0m:      Kappa: 0.2474\n",
      "\u001b[92mINFO 2024-11-23 22:20:41,927\u001b[0m:      F1 Score: 0.2808\n",
      "\u001b[92mINFO 2024-11-23 22:20:41,927\u001b[0m:      ROC AUC: 0.7875\n",
      "\u001b[93mWARNING 2024-11-23 22:20:41,927\u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO 2024-11-23 22:20:41,928\u001b[0m:      \n",
      "\u001b[92mINFO 2024-11-23 22:20:41,928\u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO 2024-11-23 22:20:41,928\u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[36m(ClientAppActor pid=908920)\u001b[0m /home/fredrik/BTH/DV2607/part2/flower_env/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=908920)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner, DirichletPartitioner\n",
    "from flwr.client import NumPyClient\n",
    "from flwr.common import Context, NDArrays, Scalar, ndarrays_to_parameters, parameters_to_ndarrays, EvaluateRes, FitRes\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedProx  # Changed from FedAvg to FedProx\n",
    "from flwr.simulation import run_simulation\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, Tuple, List\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common.logger import log\n",
    "from logging import INFO\n",
    "\n",
    "# Additional imports for plotting and data saving\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Define constants\n",
    "NUM_CLIENTS = 5\n",
    "NUM_ROUNDS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Helper function to determine device\n",
    "def get_device():\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Function to run simulation for a given scenario\n",
    "def run_simulation_scenario(ATTACKER_IDS, USE_IID):\n",
    "    # Define partitioner based on IID or non-IID\n",
    "    if USE_IID:\n",
    "        # IID Partitioning\n",
    "        partitioner = IidPartitioner(num_partitions=NUM_CLIENTS)\n",
    "    else:\n",
    "        # Non-IID Partitioning using Dirichlet distribution\n",
    "        alpha = 1.0  # Adjust alpha for desired heterogeneity\n",
    "        partitioner = DirichletPartitioner(num_partitions=NUM_CLIENTS, alpha=alpha, partition_by=\"label\")\n",
    "\n",
    "    # Load the CIFAR-10 dataset and partition it\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": partitioner})\n",
    "\n",
    "    def get_cifar10_dataloaders(cifar10_dataset, batch_size: int):\n",
    "        \"\"\"\n",
    "        Function to handle CIFAR-10 data loaders.\n",
    "        Applies appropriate transformations for CIFAR-10 images.\n",
    "        \"\"\"\n",
    "        # CIFAR-10 normalization parameters\n",
    "        pytorch_transforms = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "\n",
    "        # Prepare transformation functions\n",
    "        def apply_transforms(batch):\n",
    "            \"\"\"Apply transforms to the partition from FederatedDataset.\"\"\"\n",
    "            batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "            return batch\n",
    "\n",
    "        cifar10_dataset = cifar10_dataset.with_transform(apply_transforms)\n",
    "\n",
    "        # Construct PyTorch dataloader\n",
    "        dataloader = DataLoader(cifar10_dataset, batch_size=batch_size, shuffle=True)\n",
    "        return dataloader\n",
    "\n",
    "    # Define the neural network model suitable for CIFAR-10\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, num_classes: int) -> None:\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Changed input channels from 1 to 3 for CIFAR-10\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "            self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Adjusted for 32x32 images\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.fc3 = nn.Linear(84, num_classes)\n",
    "            self.activations = {}  # **Added to store intermediate activations**\n",
    "\n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 16 * 5 * 5)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            self.activations['fc1'] = x.detach().cpu()  # **Store activations from fc1**\n",
    "            x = F.relu(self.fc2(x))\n",
    "            self.activations['fc2'] = x.detach().cpu()  # **Store activations from fc2**\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    # Functions to set and get model parameters\n",
    "    def set_params(model, parameters):\n",
    "        \"\"\"Replace model parameters with those passed as parameters.\"\"\"\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.from_numpy(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def get_params(model):\n",
    "        \"\"\"Extract model parameters as a list of NumPy arrays.\"\"\"\n",
    "        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "    # Training function with label flipping for attackers and proximal term\n",
    "    def train(net, trainloader, optimizer, device=\"cpu\", is_attacker=False, global_params=None, mu=0.1):\n",
    "        \"\"\"Train the network on the training set with optional proximal term.\"\"\"\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        net.to(device)\n",
    "        net.train()\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"].to(device), batch[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            if is_attacker:\n",
    "                # Flip labels for attackers (simple label flipping)\n",
    "                labels = (labels + 1) % 10\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            if global_params is not None:\n",
    "                # Add proximal term\n",
    "                proximal_loss = 0.0\n",
    "                for param, global_param in zip(net.parameters(), global_params.values()):\n",
    "                    proximal_loss += torch.norm(param - global_param.to(device))**2\n",
    "                loss += (mu / 2) * proximal_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Testing function with metric calculations\n",
    "    def test(net, testloader, device):\n",
    "        \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        net.to(device)\n",
    "        net.eval()\n",
    "        correct, loss = 0, 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_outputs = []\n",
    "        with torch.no_grad():\n",
    "            for batch in testloader:\n",
    "                images, labels = batch[\"img\"].to(device), batch[\"label\"].to(device)\n",
    "                outputs = net(images)\n",
    "                loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_outputs.extend(outputs.cpu().numpy())\n",
    "        accuracy = correct / len(testloader.dataset)\n",
    "\n",
    "        # Compute metrics\n",
    "        kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "        # Check if there are at least two classes in y_true\n",
    "        unique_classes = np.unique(all_labels)\n",
    "        if len(unique_classes) > 1:\n",
    "            try:\n",
    "                all_labels_bin = label_binarize(all_labels, classes=list(range(10)))\n",
    "                all_outputs_array = np.array(all_outputs)\n",
    "                roc_auc = roc_auc_score(all_labels_bin, all_outputs_array, average='macro', multi_class='ovr')\n",
    "            except ValueError:\n",
    "                roc_auc = float('nan')  # Assign NaN if ROC AUC cannot be computed\n",
    "        else:\n",
    "            roc_auc = float('nan')  # Assign NaN if only one class is present\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"kappa\": kappa,\n",
    "            \"f1_score\": f1,\n",
    "            \"roc_auc\": roc_auc,\n",
    "        }\n",
    "        return loss, accuracy, metrics\n",
    "\n",
    "    # Initialize metrics lists\n",
    "    rounds_list = []\n",
    "    accuracy_list = []\n",
    "    kappa_list = []\n",
    "    f1_list = []\n",
    "    roc_auc_list = []\n",
    "\n",
    "    # Define the FlowerClient class\n",
    "    class FlowerClient(NumPyClient):\n",
    "        def __init__(self, trainloader, valloader, is_attacker=False) -> None:\n",
    "            super().__init__()\n",
    "            self.trainloader = trainloader\n",
    "            self.valloader = valloader\n",
    "            self.model = Net(num_classes=10)\n",
    "            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.is_attacker = is_attacker\n",
    "            self.model.to(self.device)\n",
    "\n",
    "        def fit(self, parameters, config):\n",
    "            \"\"\"Train the model locally with FedProx proximal term.\"\"\"\n",
    "            # Set model parameters\n",
    "            set_params(self.model, parameters)\n",
    "\n",
    "            # Extract global parameters from config\n",
    "            global_params = OrderedDict(\n",
    "                (k, torch.tensor(v)) for k, v in zip(self.model.state_dict().keys(), parameters)\n",
    "            )\n",
    "\n",
    "            # Get proximal_mu from config\n",
    "            mu = config.get(\"proximal_mu\", 0.1)  # Default to 0.1 if not set\n",
    "\n",
    "            # Define the optimizer\n",
    "            optim = torch.optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "            # Train the model with proximal term\n",
    "            train(\n",
    "                self.model,\n",
    "                self.trainloader,\n",
    "                optim,\n",
    "                self.device,\n",
    "                is_attacker=self.is_attacker,\n",
    "                global_params=global_params,\n",
    "                mu=mu  # Proximal term coefficient\n",
    "            )\n",
    "\n",
    "            # Return updated parameters\n",
    "            return get_params(self.model), len(self.trainloader.dataset), {}\n",
    "\n",
    "        def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
    "            \"\"\"Evaluate the model locally.\"\"\"\n",
    "            set_params(self.model, parameters)\n",
    "            loss, accuracy, metrics = test(self.model, self.valloader, self.device)\n",
    "            return float(loss), len(self.valloader.dataset), metrics\n",
    "\n",
    "    # Define the client function\n",
    "    def client_fn(context: Context):\n",
    "        \"\"\"Create a Flower client representing a participant in the federated learning.\"\"\"\n",
    "        partition_id = int(context.node_config[\"partition-id\"])\n",
    "        partition = fds.load_partition(partition_id, \"train\")\n",
    "        # Partition into train/validation\n",
    "        partition_train_val = partition.train_test_split(test_size=0.1, seed=42)\n",
    "        # Get dataloaders\n",
    "        trainloader = get_cifar10_dataloaders(partition_train_val[\"train\"], batch_size=BATCH_SIZE)\n",
    "        valloader = get_cifar10_dataloaders(partition_train_val[\"test\"], batch_size=BATCH_SIZE)\n",
    "        # Determine if the client is an attacker\n",
    "        is_attacker = partition_id in ATTACKER_IDS\n",
    "        return FlowerClient(trainloader=trainloader, valloader=valloader, is_attacker=is_attacker).to_client()\n",
    "\n",
    "    # Define function to provide fit config with proximal_mu\n",
    "    def fit_config(rnd: int):\n",
    "        \"\"\"Return training configuration dict for each round.\"\"\"\n",
    "        return {\"proximal_mu\": 0.1}  # Set proximal_mu value\n",
    "\n",
    "    # === ADDITIONAL FUNCTIONS FOR FEDDEFENDER DEFENSE ===\n",
    "    # Function to generate synthetic inputs\n",
    "    def generate_synthetic_inputs(num_inputs, input_shape):\n",
    "        \"\"\"Generate random synthetic inputs.\"\"\"\n",
    "        synthetic_inputs = []\n",
    "        for _ in range(num_inputs):\n",
    "            synthetic_input = torch.randn(*input_shape)\n",
    "            synthetic_inputs.append(synthetic_input)\n",
    "        return synthetic_inputs\n",
    "\n",
    "    # Function to perform differential testing\n",
    "    def differential_testing(client_models, synthetic_inputs):\n",
    "        \"\"\"\n",
    "        Perform differential testing on client models using synthetic inputs.\n",
    "        Return a list of client IDs identified as potential malicious and their confidence scores.\n",
    "        \"\"\"\n",
    "        activation_records = {cid: [] for cid in client_models.keys()}\n",
    "\n",
    "        # Collect activations for each client on each synthetic input\n",
    "        for synthetic_input in synthetic_inputs:\n",
    "            activations = {}\n",
    "            for cid, model in client_models.items():\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    _ = model(synthetic_input.unsqueeze(0).to(next(model.parameters()).device))\n",
    "                    # Concatenate activations from multiple layers\n",
    "                    activation = np.concatenate([\n",
    "                        model.activations['fc1'].cpu().numpy().flatten(),\n",
    "                        model.activations['fc2'].cpu().numpy().flatten()\n",
    "                    ])\n",
    "                    activations[cid] = activation\n",
    "\n",
    "            # Compute pairwise Euclidean distances\n",
    "            for cid in client_models.keys():\n",
    "                deviations = []\n",
    "                for other_cid in client_models.keys():\n",
    "                    if cid != other_cid:\n",
    "                        diff = np.linalg.norm(activations[cid] - activations[other_cid])\n",
    "                        deviations.append(diff)\n",
    "                avg_deviation = np.mean(deviations)\n",
    "                activation_records[cid].append(avg_deviation)\n",
    "\n",
    "        # Calculate mean and standard deviation across all deviations\n",
    "        all_avg_devs = [np.mean(devs) for devs in activation_records.values()]\n",
    "        mean_dev = np.mean(all_avg_devs)\n",
    "        std_dev = np.std(all_avg_devs)\n",
    "\n",
    "        # Set dynamic threshold (e.g., mean + 2 * std)\n",
    "        threshold = mean_dev + 2 * std_dev\n",
    "\n",
    "        # Normalize Malicious Confidence Scores and identify malicious clients\n",
    "        malicious_confidence = {}\n",
    "        malicious_clients = []\n",
    "        for cid, deviations in activation_records.items():\n",
    "            avg_dev = np.mean(deviations)\n",
    "            normalized_conf = avg_dev / len(synthetic_inputs)  # Normalize based on number of inputs\n",
    "            malicious_confidence[cid] = normalized_conf\n",
    "            if normalized_conf > threshold:\n",
    "                malicious_clients.append(cid)\n",
    "\n",
    "        return malicious_clients, malicious_confidence, threshold\n",
    "\n",
    "    # Define custom strategy to log metrics and include FedDefender defense\n",
    "    class CustomFedProx(FedProx):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            self.rounds_list = kwargs.pop('rounds_list')\n",
    "            self.accuracy_list = kwargs.pop('accuracy_list')\n",
    "            self.kappa_list = kwargs.pop('kappa_list')\n",
    "            self.f1_list = kwargs.pop('f1_list')\n",
    "            self.roc_auc_list = kwargs.pop('roc_auc_list')\n",
    "            self.proximal_mu = kwargs.pop('proximal_mu', 0.1)  # Proximal term coefficient\n",
    "            super().__init__(*args, proximal_mu=self.proximal_mu, **kwargs)  # Pass proximal_mu to FedProx\n",
    "\n",
    "        def aggregate_fit(\n",
    "            self,\n",
    "            rnd: int,\n",
    "            results: List[Tuple[ClientProxy, FitRes]],\n",
    "            failures: List[BaseException],\n",
    "        ):\n",
    "            \"\"\"Aggregate model updates from clients with FedDefender defense.\"\"\"\n",
    "            if not results:\n",
    "                return None\n",
    "\n",
    "            # Determine the minimum number of training examples across clients **before** adjustments\n",
    "            min_nk = min([fit_res.num_examples for _, fit_res in results])\n",
    "\n",
    "            # Convert client updates to models\n",
    "            client_models = {}\n",
    "            for client_proxy, fit_res in results:\n",
    "                parameters = fit_res.parameters\n",
    "                model = Net(num_classes=10)\n",
    "                set_params(model, parameters_to_ndarrays(parameters))\n",
    "                client_models[client_proxy.cid] = model\n",
    "\n",
    "            # Generate synthetic inputs\n",
    "            synthetic_inputs = generate_synthetic_inputs(num_inputs=20, input_shape=(3, 32, 32))  # **Increased number for robustness**\n",
    "\n",
    "            # Perform differential testing\n",
    "            malicious_clients, malicious_confidence, threshold = differential_testing(client_models, synthetic_inputs)\n",
    "\n",
    "            # Log detected malicious clients and threshold\n",
    "            if malicious_clients:\n",
    "                log(INFO, f\"Detected malicious clients in round {rnd}: {malicious_clients} with threshold {threshold:.4f}\")\n",
    "\n",
    "            # Adjust client contributions\n",
    "            adjusted_results = []\n",
    "            for client_proxy, fit_res in results:\n",
    "                cid = client_proxy.cid\n",
    "                confidence = malicious_confidence.get(cid, 0)\n",
    "                if cid in malicious_clients:\n",
    "                    # Completely eliminate the client's contribution\n",
    "                    fit_res.num_examples = 0\n",
    "                else:\n",
    "                    # Proportionally reduce contributions based on confidence\n",
    "                    adjusted_contribution = int(min_nk * (1 - confidence))\n",
    "                    fit_res.num_examples = adjusted_contribution if adjusted_contribution > 0 else 1  # Ensure at least 1\n",
    "                adjusted_results.append((client_proxy, fit_res))\n",
    "\n",
    "            # Check if all clients are malicious\n",
    "            total_examples = sum([fit_res.num_examples for _, fit_res in adjusted_results])\n",
    "            if total_examples == 0:\n",
    "                log(INFO, f\"All clients detected as malicious in round {rnd}. Reverting to original contributions.\")\n",
    "                adjusted_results = results  # Revert to original if all are malicious\n",
    "\n",
    "            # Proceed with aggregation using adjusted results\n",
    "            return super().aggregate_fit(rnd, adjusted_results, failures)\n",
    "\n",
    "        def aggregate_evaluate(\n",
    "            self,\n",
    "            rnd: int,\n",
    "            results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "            failures: List[BaseException],\n",
    "        ):\n",
    "            \"\"\"Aggregate evaluation results using weighted average and log metrics per round.\"\"\"\n",
    "            if not results:\n",
    "                return None, {}\n",
    "\n",
    "            # Use weighted average to aggregate metrics\n",
    "            num_examples_total = sum([r[1].num_examples for r in results])\n",
    "\n",
    "            if num_examples_total == 0:\n",
    "                log(INFO, f\"No evaluation data in round {rnd}. Skipping evaluation aggregation.\")\n",
    "                return None, {}\n",
    "\n",
    "            # Initialize sums\n",
    "            accuracy_sum = 0.0\n",
    "            kappa_sum = 0.0\n",
    "            f1_sum = 0.0\n",
    "            roc_auc_sum = 0.0\n",
    "            roc_auc_weight = 0\n",
    "\n",
    "            for _, evaluate_res in results:\n",
    "                accuracy_sum += evaluate_res.metrics.get(\"accuracy\", 0.0) * evaluate_res.num_examples\n",
    "                kappa_sum += evaluate_res.metrics.get(\"kappa\", 0.0) * evaluate_res.num_examples\n",
    "                f1_sum += evaluate_res.metrics.get(\"f1_score\", 0.0) * evaluate_res.num_examples\n",
    "                roc_auc = evaluate_res.metrics.get(\"roc_auc\", float('nan'))\n",
    "                if not np.isnan(roc_auc):\n",
    "                    roc_auc_sum += roc_auc * evaluate_res.num_examples\n",
    "                    roc_auc_weight += evaluate_res.num_examples\n",
    "\n",
    "            # Compute weighted averages\n",
    "            accuracy = accuracy_sum / num_examples_total\n",
    "            kappa = kappa_sum / num_examples_total\n",
    "            f1 = f1_sum / num_examples_total\n",
    "            roc_auc = roc_auc_sum / roc_auc_weight if roc_auc_weight > 0 else float('nan')\n",
    "\n",
    "            # Log metrics\n",
    "            log(INFO, f\"Round {rnd} evaluation metrics:\")\n",
    "            log(INFO, f\"Accuracy: {accuracy:.4f}\")\n",
    "            log(INFO, f\"Kappa: {kappa:.4f}\")\n",
    "            log(INFO, f\"F1 Score: {f1:.4f}\")\n",
    "            if not np.isnan(roc_auc):\n",
    "                log(INFO, f\"ROC AUC: {roc_auc:.4f}\")\n",
    "            else:\n",
    "                log(INFO, f\"ROC AUC: Undefined (only one class present in y_true)\")\n",
    "\n",
    "            # Store metrics\n",
    "            self.rounds_list.append(rnd)\n",
    "            self.accuracy_list.append(accuracy)\n",
    "            self.kappa_list.append(kappa)\n",
    "            self.f1_list.append(f1)\n",
    "            self.roc_auc_list.append(roc_auc if not np.isnan(roc_auc) else 0.0)\n",
    "\n",
    "            # Return aggregated loss and metrics\n",
    "            return super().aggregate_evaluate(rnd, results, failures)\n",
    "\n",
    "    # Define the server function\n",
    "    def server_fn(context: Context):\n",
    "        # Instantiate the model\n",
    "        model = Net(num_classes=10)\n",
    "        ndarrays = get_params(model)\n",
    "        # Convert model parameters to flwr.common.Parameters\n",
    "        global_model_init = ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "        # Define the strategy with FedProx parameters\n",
    "        strategy = CustomFedProx(\n",
    "            fraction_fit=1.0,        # All clients participate in training\n",
    "            fraction_evaluate=1.0,   # All clients participate in evaluation\n",
    "            initial_parameters=global_model_init,  # Initialized global model\n",
    "            rounds_list=rounds_list,\n",
    "            accuracy_list=accuracy_list,\n",
    "            kappa_list=kappa_list,\n",
    "            f1_list=f1_list,\n",
    "            roc_auc_list=roc_auc_list,\n",
    "            proximal_mu=0.1,  # Proximal term coefficient for FedProx\n",
    "            on_fit_config_fn=fit_config  # Function to provide fit config\n",
    "        )\n",
    "\n",
    "        # Construct ServerConfig\n",
    "        config = ServerConfig(num_rounds=NUM_ROUNDS)\n",
    "\n",
    "        # Wrap everything into a ServerAppComponents object\n",
    "        return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "    # Create your ServerApp and ClientApp\n",
    "    server_app = ServerApp(server_fn=server_fn)\n",
    "    from flwr.client import ClientApp\n",
    "    client_app = ClientApp(client_fn=client_fn)\n",
    "\n",
    "    # Run the simulation\n",
    "    run_simulation(\n",
    "        server_app=server_app,\n",
    "        client_app=client_app,\n",
    "        num_supernodes=NUM_CLIENTS,\n",
    "        backend_name=\"ray\",\n",
    "        verbose_logging=True,\n",
    "    )\n",
    "\n",
    "    # After the simulation, collect the metrics\n",
    "    metrics = {\n",
    "        \"rounds\": rounds_list,\n",
    "        \"accuracy\": accuracy_list,\n",
    "        \"kappa\": kappa_list,\n",
    "        \"f1_score\": f1_list,\n",
    "        \"roc_auc\": roc_auc_list,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Function to run all scenarios\n",
    "def run_all_scenarios():\n",
    "    scenarios = [\n",
    "        {\"name\": \"Baseline_IID\", \"ATTACKER_IDS\": [], \"USE_IID\": True},\n",
    "        {\"name\": \"One_Attacker_IID\", \"ATTACKER_IDS\": [0], \"USE_IID\": True},\n",
    "        {\"name\": \"Two_Attackers_IID\", \"ATTACKER_IDS\": [0, 1], \"USE_IID\": True},\n",
    "        {\"name\": \"Baseline_NonIID\", \"ATTACKER_IDS\": [], \"USE_IID\": False},\n",
    "        {\"name\": \"One_Attacker_NonIID\", \"ATTACKER_IDS\": [0], \"USE_IID\": False},\n",
    "        {\"name\": \"Two_Attackers_NonIID\", \"ATTACKER_IDS\": [0, 1], \"USE_IID\": False},\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        print(f\"\\nRunning Scenario: {scenario['name']}\")\n",
    "        metrics = run_simulation_scenario(scenario[\"ATTACKER_IDS\"], scenario[\"USE_IID\"])\n",
    "        results[scenario[\"name\"]] = metrics\n",
    "\n",
    "        # Plot the metrics\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(metrics[\"rounds\"], metrics[\"accuracy\"], marker='o', color='blue')\n",
    "        plt.title(f\"Accuracy Over Rounds ({scenario['name']})\")\n",
    "        plt.xlabel('Round')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(metrics[\"rounds\"], metrics[\"kappa\"], marker='o', color='green')\n",
    "        plt.title(f\"Kappa Over Rounds ({scenario['name']})\")\n",
    "        plt.xlabel('Round')\n",
    "        plt.ylabel('Kappa')\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(metrics[\"rounds\"], metrics[\"f1_score\"], marker='o', color='red')\n",
    "        plt.title(f\"F1 Score Over Rounds ({scenario['name']})\")\n",
    "        plt.xlabel('Round')\n",
    "        plt.ylabel(\"F1 Score\")\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(metrics[\"rounds\"], metrics[\"roc_auc\"], marker='o', color='purple')\n",
    "        plt.title(f\"ROC AUC Over Rounds ({scenario['name']})\")\n",
    "        plt.xlabel('Round')\n",
    "        plt.ylabel(\"ROC AUC\")\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Save metrics to CSV\n",
    "        df = pd.DataFrame(metrics)\n",
    "        df.to_csv(f\"{scenario['name']}_metrics.csv\", index=False)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run all scenarios\n",
    "results = run_all_scenarios()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
