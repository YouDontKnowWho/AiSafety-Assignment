{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fredrik/BTH/DV2607/part2/flower_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-22 18:15:55,875\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\u001b[94mDEBUG 2024-11-22 18:15:55,914\u001b[0m:     Asyncio event loop already running.\n",
      "\u001b[94mDEBUG 2024-11-22 18:15:55,916\u001b[0m:     Logger propagate set to False\n",
      "\u001b[94mDEBUG 2024-11-22 18:15:55,916\u001b[0m:     Pre-registering run with id 16099003574598300099\n",
      "\u001b[94mDEBUG 2024-11-22 18:15:55,917\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-11-22 18:15:55,918\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-11-22 18:15:55,919\u001b[0m:     Buffer time delay: 5s\n",
      "\u001b[92mINFO 2024-11-22 18:15:55,922\u001b[0m:      Starting Flower ServerApp, config: num_rounds=50, no round_timeout\n",
      "\u001b[92mINFO 2024-11-22 18:15:55,923\u001b[0m:      \n",
      "\u001b[92mINFO 2024-11-22 18:15:55,923\u001b[0m:      [INIT]\n",
      "\u001b[92mINFO 2024-11-22 18:15:55,924\u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO 2024-11-22 18:15:55,924\u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO 2024-11-22 18:15:55,925\u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO 2024-11-22 18:15:55,925\u001b[0m:      \n",
      "\u001b[92mINFO 2024-11-22 18:15:55,926\u001b[0m:      [ROUND 1]\n",
      "\u001b[94mDEBUG 2024-11-22 18:16:00,920\u001b[0m:     Using InMemoryState\n",
      "\u001b[94mDEBUG 2024-11-22 18:16:00,921\u001b[0m:     Registered 5 nodes\n",
      "\u001b[94mDEBUG 2024-11-22 18:16:00,921\u001b[0m:     Supported backends: ['ray']\n",
      "\u001b[94mDEBUG 2024-11-22 18:16:00,922\u001b[0m:     Initialising: RayBackend\n",
      "\u001b[94mDEBUG 2024-11-22 18:16:00,922\u001b[0m:     Backend config: {'init_args': {}, 'client_resources': {'num_cpus': 2, 'num_gpus': 0}, 'actor': {'tensorflow': 0}}\n",
      "2024-11-22 18:16:01,607\tINFO worker.py:1819 -- Started a local Ray instance.\n",
      "\u001b[92mINFO 2024-11-22 18:16:02,154\u001b[0m:      configure_fit: strategy sampled 2 clients (out of 5)\n",
      "\u001b[94mDEBUG 2024-11-22 18:16:02,169\u001b[0m:     Constructed ActorPool with: 16 actors\n",
      "\u001b[94mDEBUG 2024-11-22 18:16:02,169\u001b[0m:     Using InMemoryState\n",
      "\u001b[36m(ClientAppActor pid=2973619)\u001b[0m /home/fredrik/BTH/DV2607/part2/flower_env/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=2973619)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[92mINFO 2024-11-22 18:16:11,675\u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[93mWARNING 2024-11-22 18:16:11,678\u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO 2024-11-22 18:16:11,679\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
      "\u001b[36m(ClientAppActor pid=2973619)\u001b[0m /home/fredrik/BTH/DV2607/part2/flower_env/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2973619)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO 2024-11-22 18:16:18,392\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO 2024-11-22 18:16:18,392\u001b[0m:      Round 1 evaluation metrics:\n",
      "\u001b[92mINFO 2024-11-22 18:16:18,393\u001b[0m:      Accuracy: 0.3410\n",
      "\u001b[92mINFO 2024-11-22 18:16:18,393\u001b[0m:      Kappa: 0.2672\n",
      "\u001b[92mINFO 2024-11-22 18:16:18,393\u001b[0m:      F1 Score: 0.3273\n",
      "\u001b[92mINFO 2024-11-22 18:16:18,393\u001b[0m:      ROC AUC: 0.7827\n",
      "\u001b[93mWARNING 2024-11-22 18:16:18,394\u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO 2024-11-22 18:16:18,394\u001b[0m:      \n",
      "\u001b[92mINFO 2024-11-22 18:16:18,394\u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO 2024-11-22 18:16:18,395\u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner, DirichletPartitioner\n",
    "from flwr.client import NumPyClient\n",
    "from flwr.common import Context, NDArrays, Scalar, ndarrays_to_parameters, EvaluateRes\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, Tuple, List\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common.logger import log\n",
    "from logging import INFO\n",
    "\n",
    "# Define constants\n",
    "NUM_CLIENTS = 5\n",
    "NUM_ROUNDS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Define the number of attackers\n",
    "ATTACKER_IDS = [0]  # For one attacker, set to [0]; for two attackers, set to [0, 1]\n",
    "\n",
    "# Define whether to use IID or non-IID data\n",
    "USE_IID = False  # Set to False for non-IID data\n",
    "\n",
    "# Define partitioner based on IID or non-IID\n",
    "if USE_IID:\n",
    "    # IID Partitioning\n",
    "    partitioner = IidPartitioner(num_partitions=NUM_CLIENTS)\n",
    "else:\n",
    "    # Non-IID Partitioning using Dirichlet distribution\n",
    "    alpha = 0.1  # Smaller alpha means more heterogeneity\n",
    "    partitioner = DirichletPartitioner(num_partitions=NUM_CLIENTS, alpha=alpha, partition_by=\"label\")\n",
    "\n",
    "# Load the CIFAR-10 dataset and partition it\n",
    "fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": partitioner})  # Changed from \"ylecun/mnist\" to \"cifar10\"\n",
    "\n",
    "def get_cifar10_dataloaders(cifar10_dataset, batch_size: int):\n",
    "    \"\"\"\n",
    "    Updated function to handle CIFAR-10 data loaders.\n",
    "    Applies appropriate transformations for CIFAR-10 images.\n",
    "    \"\"\"\n",
    "    # CIFAR-10 normalization parameters\n",
    "    pytorch_transforms = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "    # Prepare transformation functions\n",
    "    def apply_transforms(batch):\n",
    "        \"\"\"Apply transforms to the partition from FederatedDataset.\"\"\"\n",
    "        # Changed 'image' to 'img' to match CIFAR-10 dataset keys\n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    cifar10_dataset = cifar10_dataset.with_transform(apply_transforms)\n",
    "\n",
    "    # Construct PyTorch dataloader\n",
    "    dataloader = DataLoader(cifar10_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "# Define the neural network model suitable for CIFAR-10\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # Changed input channels from 1 to 3 for CIFAR-10\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Adjusted input features from 16*4*4 to 16*5*5 for 32x32 images\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)  # Adjusted to match the new input size\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Functions to set and get model parameters\n",
    "def set_params(model, parameters):\n",
    "    \"\"\"Replace model parameters with those passed as parameters.\"\"\"\n",
    "    params_dict = zip(model.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.from_numpy(v) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def get_params(model):\n",
    "    \"\"\"Extract model parameters as a list of NumPy arrays.\"\"\"\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "# Training function with label flipping for attackers\n",
    "def train(net, trainloader, optimizer, device=\"cpu\", is_attacker=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    for batch in trainloader:\n",
    "        images, labels = batch[\"img\"].to(device), batch[\"label\"].to(device)  # Changed 'image' to 'img'\n",
    "        optimizer.zero_grad()\n",
    "        if is_attacker:\n",
    "            # Flip labels for attackers\n",
    "            labels = (9 - labels)  # Simple label flipping\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Testing function with metric calculations\n",
    "def test(net, testloader, device):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    correct, loss = 0, 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"].to(device), batch[\"label\"].to(device)  # Changed 'image' to 'img'\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "    accuracy = correct / len(testloader.dataset)\n",
    "\n",
    "    # Compute metrics\n",
    "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    # Check if there are at least two classes in y_true\n",
    "    unique_classes = np.unique(all_labels)\n",
    "    if len(unique_classes) > 1:\n",
    "        try:\n",
    "            all_labels_bin = label_binarize(all_labels, classes=list(range(10)))\n",
    "            all_outputs_array = np.array(all_outputs)\n",
    "            roc_auc = roc_auc_score(all_labels_bin, all_outputs_array, average='macro', multi_class='ovr')\n",
    "        except ValueError:\n",
    "            roc_auc = float('nan')  # Assign NaN if ROC AUC cannot be computed\n",
    "    else:\n",
    "        roc_auc = float('nan')  # Assign NaN if only one class is present\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"kappa\": kappa,\n",
    "        \"f1_score\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "    }\n",
    "    return loss, accuracy, metrics\n",
    "\n",
    "# Define the FlowerClient class\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, trainloader, valloader, is_attacker=False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.model = Net(num_classes=10)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.is_attacker = is_attacker\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Train the model locally.\"\"\"\n",
    "        # Set model parameters\n",
    "        set_params(self.model, parameters)\n",
    "\n",
    "        # Define the optimizer\n",
    "        optim = torch.optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "        # Train the model\n",
    "        train(self.model, self.trainloader, optim, self.device, is_attacker=self.is_attacker)\n",
    "\n",
    "        # Return updated parameters\n",
    "        return get_params(self.model), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
    "        \"\"\"Evaluate the model locally.\"\"\"\n",
    "        set_params(self.model, parameters)\n",
    "        loss, accuracy, metrics = test(self.model, self.valloader, self.device)\n",
    "        return float(loss), len(self.valloader.dataset), metrics\n",
    "\n",
    "# Define the client function\n",
    "def client_fn(context: Context):\n",
    "    \"\"\"Create a Flower client representing a participant in the federated learning.\"\"\"\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    partition = fds.load_partition(partition_id, \"train\")\n",
    "    # Partition into train/validation\n",
    "    partition_train_val = partition.train_test_split(test_size=0.1, seed=42)\n",
    "    # Get dataloaders\n",
    "    trainloader = get_cifar10_dataloaders(partition_train_val[\"train\"], batch_size=BATCH_SIZE)  # Changed function name\n",
    "    valloader = get_cifar10_dataloaders(partition_train_val[\"test\"], batch_size=BATCH_SIZE)    # Changed function name\n",
    "    # Determine if the client is an attacker\n",
    "    is_attacker = partition_id in ATTACKER_IDS\n",
    "    return FlowerClient(trainloader=trainloader, valloader=valloader, is_attacker=is_attacker).to_client()\n",
    "\n",
    "# Define custom strategy to log metrics\n",
    "class CustomFedAvg(FedAvg):\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[BaseException],\n",
    "    ):\n",
    "        \"\"\"Aggregate evaluation results using weighted average and log metrics per round.\"\"\"\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        \n",
    "        # Use weighted average to aggregate metrics\n",
    "        num_examples_total = sum([r[1].num_examples for r in results])\n",
    "\n",
    "        # Initialize sums\n",
    "        accuracy_sum = 0.0\n",
    "        kappa_sum = 0.0\n",
    "        f1_sum = 0.0\n",
    "        roc_auc_sum = 0.0\n",
    "        roc_auc_weight = 0\n",
    "\n",
    "        for _, evaluate_res in results:\n",
    "            accuracy_sum += evaluate_res.metrics.get(\"accuracy\", 0.0) * evaluate_res.num_examples\n",
    "            kappa_sum += evaluate_res.metrics.get(\"kappa\", 0.0) * evaluate_res.num_examples\n",
    "            f1_sum += evaluate_res.metrics.get(\"f1_score\", 0.0) * evaluate_res.num_examples\n",
    "            roc_auc = evaluate_res.metrics.get(\"roc_auc\", float('nan'))\n",
    "            if not np.isnan(roc_auc):\n",
    "                roc_auc_sum += roc_auc * evaluate_res.num_examples\n",
    "                roc_auc_weight += evaluate_res.num_examples\n",
    "\n",
    "        # Compute weighted averages\n",
    "        accuracy = accuracy_sum / num_examples_total\n",
    "        kappa = kappa_sum / num_examples_total\n",
    "        f1 = f1_sum / num_examples_total\n",
    "        roc_auc = roc_auc_sum / roc_auc_weight if roc_auc_weight > 0 else float('nan')\n",
    "\n",
    "        # Log metrics\n",
    "        log(INFO, f\"Round {rnd} evaluation metrics:\")\n",
    "        log(INFO, f\"Accuracy: {accuracy:.4f}\")\n",
    "        log(INFO, f\"Kappa: {kappa:.4f}\")\n",
    "        log(INFO, f\"F1 Score: {f1:.4f}\")\n",
    "        if not np.isnan(roc_auc):\n",
    "            log(INFO, f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        else:\n",
    "            log(INFO, f\"ROC AUC: Undefined (only one class present in y_true)\")\n",
    "\n",
    "        # Return aggregated loss and metrics\n",
    "        return super().aggregate_evaluate(rnd, results, failures)\n",
    "\n",
    "# Define the server function\n",
    "def server_fn(context: Context):\n",
    "    # Instantiate the model\n",
    "    model = Net(num_classes=10)\n",
    "    ndarrays = get_params(model)\n",
    "    # Convert model parameters to flwr.common.Parameters\n",
    "    global_model_init = ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    # Define the strategy\n",
    "    strategy = CustomFedAvg(\n",
    "        fraction_fit=1.0,        # All clients participate in training\n",
    "        fraction_evaluate=1.0,   # All clients participate in evaluation\n",
    "        initial_parameters=global_model_init,  # Initialized global model\n",
    "    )\n",
    "\n",
    "    # Construct ServerConfig\n",
    "    config = ServerConfig(num_rounds=NUM_ROUNDS)\n",
    "\n",
    "    # Wrap everything into a ServerAppComponents object\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# Create your ServerApp and ClientApp\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "from flwr.client import ClientApp\n",
    "client_app = ClientApp(client_fn=client_fn)\n",
    "\n",
    "# Run the simulation\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_name=\"ray\",\n",
    "    verbose_logging=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
